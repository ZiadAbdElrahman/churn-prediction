# Churn Prediction System

This project implements an end-to-end machine learning pipeline for churn prediction, with **model training, evaluation, experiment tracking, and serving** in production.

It combines:
- **XGBoost classifier** with configurable hyperparameters  
- **MLflow** for experiment tracking and logging  
- **FastAPI** service for real-time predictions and training endpoint  
- **Docker** and **uv** for reproducible builds and environments  

---

## ğŸš€ Features

- **Training**
  - Train an XGBoost churn model with configurable hyperparameters.
  - Logs metrics (AUC-PR, logloss, classification report) and artifacts to MLflow.
  - Stores model, threshold, and metadata under `artifacts/`.

- **Serving**
  - `/train` endpoint to retrain the model on demand.
  - `/predict` endpoint for batch or single predictions.

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ train.py          # Training script
â”‚   â”œâ”€â”€ model_io.py       # Save/load artifacts
â”‚   â”œâ”€â”€ dependencies.py   # Config & shared utilities
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # FastAPI entrypoint
â”‚   â”œâ”€â”€ controller.py     # API endpoints
â”‚
â”œâ”€â”€ artifacts/            # Models, references, metrics
â”œâ”€â”€ Makefile              # Reproducible commands
â”œâ”€â”€ pyproject.toml        # Project dependencies (uv / PEP 621)
â”œâ”€â”€ .pre-commit-config.yaml  # Code quality hooks
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

Clone the repo and install dependencies with [uv](https://github.com/astral-sh/uv):

```bash
uv sync
```

Or with pip:

```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Dataset
Before running training or serving, you need to download the data file in teh /data folder:
```bash
customer_churn.json
```


## ğŸ—ï¸ Usage

### 1. Train a model
```bash
make train
```

Artifacts saved to `artifacts/`, including:
- `model.pkl` â€“ trained model  
- `metadata.json` â€“ metrics + threshold  

### 2. Run API service
```bash
make serve
```
API runs at `http://0.0.0.0:8000/`

Endpoints:
- `POST /train` â†’ retrain model (saves artifacts + logs to MLflow).  
- `POST /predict` â†’ predict churn probabilities.  

Example `curl`:

```bash
curl -X POST "http://0.0.0.0:8000/predict"   -H "Content-Type: application/json"   -d '{"user_id": 123, "feature1": 5.0, "feature2": 0.7}'
```

---

## ğŸ“Š MLflow Tracking

Each training run logs:
- Metrics (PR-AUC, recall, precision)
- Parameters (XGBoost hyperparams)
- Artifacts (model, reports)

Run UI:
```bash
mlflow ui
```

---

## ğŸ§¹ Development

This repo uses **pre-commit hooks** for code quality.

Install hooks:
```bash
pre-commit install
```

Run checks:
```bash
pre-commit run --all-files
```

---

## ğŸ“Œ TODO / Extensions

- Add monitoring system:
  - **Data drift** detection (PSI, KS test per feature).  
  - **Concept drift** detection (performance decay).  
  - Automated performance tracking.  
- Integrate retraining job on severe drift.  
- Integrate alerting (Slack/Email).  
- Add dashboard for monitoring visualization.  

---
